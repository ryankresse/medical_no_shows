{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('no_show_prev_adj_2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_acc(rf, X, y):\n",
    "    return (rf.predict(X) == y).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>appointmentid</th>\n",
       "      <th>gender</th>\n",
       "      <th>scheduledday</th>\n",
       "      <th>appointmentday</th>\n",
       "      <th>age</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>hipertension</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>no_show</th>\n",
       "      <th>scheduledday_year</th>\n",
       "      <th>scheduledday_month</th>\n",
       "      <th>scheduledday_dow</th>\n",
       "      <th>appointmentday_year</th>\n",
       "      <th>appointmentday_month</th>\n",
       "      <th>appointmentday_dow</th>\n",
       "      <th>scheduledday_hour</th>\n",
       "      <th>date_diff</th>\n",
       "      <th>prev_no_show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29872499824296</td>\n",
       "      <td>5642903</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29 18:38:08</td>\n",
       "      <td>2016-04-29 00:00:00</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>725775968562</td>\n",
       "      <td>5521232</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-03-29 11:09:08</td>\n",
       "      <td>2016-04-29 00:00:00</td>\n",
       "      <td>33</td>\n",
       "      <td>MARIA ORTIZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>94755722517728</td>\n",
       "      <td>5521230</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-03-29 11:08:52</td>\n",
       "      <td>2016-04-29 00:00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>MARIA ORTIZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>35387553979251</td>\n",
       "      <td>5523393</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-03-29 17:04:40</td>\n",
       "      <td>2016-04-29 00:00:00</td>\n",
       "      <td>69</td>\n",
       "      <td>MARIA ORTIZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>732498986588399</td>\n",
       "      <td>5642808</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29 17:21:24</td>\n",
       "      <td>2016-04-29 00:00:00</td>\n",
       "      <td>65</td>\n",
       "      <td>MARIA ORTIZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            patientid  appointmentid gender         scheduledday  \\\n",
       "0      29872499824296        5642903      F  2016-04-29 18:38:08   \n",
       "2151     725775968562        5521232      M  2016-03-29 11:09:08   \n",
       "2152   94755722517728        5521230      F  2016-03-29 11:08:52   \n",
       "2153   35387553979251        5523393      F  2016-03-29 17:04:40   \n",
       "2154  732498986588399        5642808      F  2016-04-29 17:21:24   \n",
       "\n",
       "           appointmentday  age    neighbourhood  scholarship  hipertension  \\\n",
       "0     2016-04-29 00:00:00   62  JARDIM DA PENHA            0             1   \n",
       "2151  2016-04-29 00:00:00   33      MARIA ORTIZ            0             0   \n",
       "2152  2016-04-29 00:00:00   50      MARIA ORTIZ            0             0   \n",
       "2153  2016-04-29 00:00:00   69      MARIA ORTIZ            0             0   \n",
       "2154  2016-04-29 00:00:00   65      MARIA ORTIZ            0             0   \n",
       "\n",
       "      diabetes      ...       no_show  scheduledday_year  scheduledday_month  \\\n",
       "0            0      ...             0               2016                   4   \n",
       "2151         0      ...             0               2016                   3   \n",
       "2152         0      ...             0               2016                   3   \n",
       "2153         0      ...             0               2016                   3   \n",
       "2154         0      ...             0               2016                   4   \n",
       "\n",
       "      scheduledday_dow  appointmentday_year  appointmentday_month  \\\n",
       "0                    4                 2016                     4   \n",
       "2151                 1                 2016                     4   \n",
       "2152                 1                 2016                     4   \n",
       "2153                 1                 2016                     4   \n",
       "2154                 4                 2016                     4   \n",
       "\n",
       "      appointmentday_dow  scheduledday_hour  date_diff  prev_no_show  \n",
       "0                      4                 18          0           0.0  \n",
       "2151                   4                 11         31           0.0  \n",
       "2152                   4                 11         31           0.0  \n",
       "2153                   4                 17         31           0.0  \n",
       "2154                   4                 17          0           0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patientid               0\n",
       "appointmentid           0\n",
       "gender                  0\n",
       "scheduledday            0\n",
       "appointmentday          0\n",
       "age                     0\n",
       "neighbourhood           0\n",
       "scholarship             0\n",
       "hipertension            0\n",
       "diabetes                0\n",
       "alcoholism              0\n",
       "handcap                 0\n",
       "sms_received            0\n",
       "no_show                 0\n",
       "scheduledday_year       0\n",
       "scheduledday_month      0\n",
       "scheduledday_dow        0\n",
       "appointmentday_year     0\n",
       "appointmentday_month    0\n",
       "appointmentday_dow      0\n",
       "scheduledday_hour       0\n",
       "date_diff               0\n",
       "prev_no_show            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patientid                 int64\n",
       "appointmentid             int64\n",
       "gender                   object\n",
       "scheduledday             object\n",
       "appointmentday           object\n",
       "age                       int64\n",
       "neighbourhood            object\n",
       "scholarship               int64\n",
       "hipertension              int64\n",
       "diabetes                  int64\n",
       "alcoholism                int64\n",
       "handcap                   int64\n",
       "sms_received              int64\n",
       "no_show                   int64\n",
       "scheduledday_year         int64\n",
       "scheduledday_month        int64\n",
       "scheduledday_dow          int64\n",
       "appointmentday_year       int64\n",
       "appointmentday_month      int64\n",
       "appointmentday_dow        int64\n",
       "scheduledday_hour         int64\n",
       "date_diff                 int64\n",
       "prev_no_show            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "cols = [col.strip().lower().replace('-', '_') for col in cols]\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['patientid'] = df.patientid.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ['scheduledday', 'appointmentday']:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    df[col+'_year'] = df[col].dt.year\n",
    "    df[col+'_month'] = df[col].dt.month\n",
    "    df[col+'_dow'] = df[col].dt.dayofweek\n",
    "df['scheduledday_hour'] = df.scheduledday.dt.hour\n",
    "df['date_diff'] = (df.appointmentday.dt.date - df.scheduledday.dt.date).dt.days \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['same_day'] = (df.appointmentday.dt.date == df.scheduledday.dt.date).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['patientid', 'appointmentid', 'appointmentday', 'scheduledday'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "ngb_enc = LabelEncoder()\n",
    "gen_enc = LabelEncoder()\n",
    "df['neighbourhood'] = ngb_enc.fit_transform(df.neighbourhood)\n",
    "df['gender'] = gen_enc.fit_transform(df.gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll tune a few hyperparameters following [this](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/) approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dall = xgb.DMatrix(df.drop('no_show', axis=1).values, label=df.no_show.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_param =xgb1.get_xgb_params()\n",
    "cvresult = xgb.cv(xgb_param, dall, num_boost_round=xgb1.get_params()['n_estimators'], nfold=5, metrics='error', early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.199231</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.198369</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.198697</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.198093</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.199177</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>0.000891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.199376</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.198489</td>\n",
       "      <td>0.001205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199566</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.198537</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.199204</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.198315</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.199077</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.198267</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.198815</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.197985</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.198670</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.197851</td>\n",
       "      <td>0.000656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.198905</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.197903</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.198797</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.197853</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.198733</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.197686</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.198779</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.197713</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.198625</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.197779</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.198598</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.197736</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.198553</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.197659</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.198579</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.198507</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.197747</td>\n",
       "      <td>0.000760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.198625</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.197745</td>\n",
       "      <td>0.000676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.198326</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.197591</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.198371</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.197519</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.198299</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.197489</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.198281</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.198299</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.197380</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.198299</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.197374</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.198290</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.197311</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.198254</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.197259</td>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.198353</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.197243</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.198326</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.197227</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.198218</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.197218</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.196779</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.189199</td>\n",
       "      <td>0.000677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.196779</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.189222</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.196842</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.189204</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.196896</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.189149</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.196779</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.189068</td>\n",
       "      <td>0.000676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.196869</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.189057</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.196888</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.189025</td>\n",
       "      <td>0.000665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.196851</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.188984</td>\n",
       "      <td>0.000686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.196915</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.188849</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.196861</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.188767</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.196906</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.188735</td>\n",
       "      <td>0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.196942</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.188749</td>\n",
       "      <td>0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.196933</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.188683</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.196924</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.188699</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.196933</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.188668</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.196933</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.188629</td>\n",
       "      <td>0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.196924</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.188586</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.196978</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.188548</td>\n",
       "      <td>0.000593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.196978</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.188543</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.196933</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.188505</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.196906</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.188459</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.196851</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.188466</td>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.196860</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.188435</td>\n",
       "      <td>0.000676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.196824</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.188394</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.196734</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.196788</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.188322</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.196707</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.188249</td>\n",
       "      <td>0.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.196743</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.188197</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.196779</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.188184</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.196707</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.188093</td>\n",
       "      <td>0.000624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-error-mean  test-error-std  train-error-mean  train-error-std\n",
       "0           0.199231        0.002531          0.198369         0.000634\n",
       "1           0.198697        0.002291          0.198093         0.000620\n",
       "2           0.199177        0.002334          0.198338         0.000891\n",
       "3           0.199376        0.002402          0.198489         0.001205\n",
       "4           0.199566        0.002039          0.198537         0.001275\n",
       "5           0.199204        0.001984          0.198315         0.001145\n",
       "6           0.199077        0.002057          0.198267         0.000933\n",
       "7           0.198815        0.002011          0.197985         0.000751\n",
       "8           0.198670        0.002223          0.197851         0.000656\n",
       "9           0.198905        0.002344          0.197903         0.000726\n",
       "10          0.198797        0.002243          0.197853         0.000707\n",
       "11          0.198733        0.002095          0.197686         0.000826\n",
       "12          0.198779        0.002005          0.197713         0.000878\n",
       "13          0.198625        0.002021          0.197779         0.000751\n",
       "14          0.198598        0.002174          0.197736         0.000805\n",
       "15          0.198553        0.002170          0.197659         0.000829\n",
       "16          0.198579        0.002176          0.197700         0.000782\n",
       "17          0.198507        0.002251          0.197747         0.000760\n",
       "18          0.198625        0.002170          0.197745         0.000676\n",
       "19          0.198326        0.002340          0.197591         0.000643\n",
       "20          0.198371        0.002311          0.197519         0.000731\n",
       "21          0.198299        0.002274          0.197489         0.000742\n",
       "22          0.198281        0.002290          0.197462         0.000755\n",
       "23          0.198299        0.002250          0.197380         0.000732\n",
       "24          0.198299        0.002143          0.197374         0.000780\n",
       "25          0.198290        0.002090          0.197311         0.000790\n",
       "26          0.198254        0.002125          0.197259         0.000794\n",
       "27          0.198353        0.002084          0.197243         0.000803\n",
       "28          0.198326        0.002133          0.197227         0.000767\n",
       "29          0.198218        0.002098          0.197218         0.000758\n",
       "..               ...             ...               ...              ...\n",
       "222         0.196779        0.002507          0.189199         0.000677\n",
       "223         0.196779        0.002461          0.189222         0.000705\n",
       "224         0.196842        0.002462          0.189204         0.000670\n",
       "225         0.196896        0.002465          0.189149         0.000685\n",
       "226         0.196779        0.002499          0.189068         0.000676\n",
       "227         0.196869        0.002493          0.189057         0.000658\n",
       "228         0.196888        0.002485          0.189025         0.000665\n",
       "229         0.196851        0.002486          0.188984         0.000686\n",
       "230         0.196915        0.002437          0.188849         0.000689\n",
       "231         0.196861        0.002447          0.188767         0.000612\n",
       "232         0.196906        0.002440          0.188735         0.000654\n",
       "233         0.196942        0.002414          0.188749         0.000648\n",
       "234         0.196933        0.002436          0.188683         0.000706\n",
       "235         0.196924        0.002435          0.188699         0.000717\n",
       "236         0.196933        0.002455          0.188668         0.000670\n",
       "237         0.196933        0.002453          0.188629         0.000648\n",
       "238         0.196924        0.002552          0.188586         0.000640\n",
       "239         0.196978        0.002527          0.188548         0.000593\n",
       "240         0.196978        0.002510          0.188543         0.000628\n",
       "241         0.196933        0.002580          0.188505         0.000703\n",
       "242         0.196906        0.002509          0.188459         0.000645\n",
       "243         0.196851        0.002533          0.188466         0.000642\n",
       "244         0.196860        0.002467          0.188435         0.000676\n",
       "245         0.196824        0.002467          0.188394         0.000703\n",
       "246         0.196734        0.002444          0.188353         0.000707\n",
       "247         0.196788        0.002431          0.188322         0.000687\n",
       "248         0.196707        0.002461          0.188249         0.000650\n",
       "249         0.196743        0.002462          0.188197         0.000634\n",
       "250         0.196779        0.002521          0.188184         0.000615\n",
       "251         0.196707        0.002465          0.188093         0.000624\n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.196707</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.188093</td>\n",
       "      <td>0.000624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-error-mean  test-error-std  train-error-mean  train-error-std\n",
       "251         0.196707        0.002465          0.188093         0.000624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresult[cvresult['test-error-mean'] == cvresult['test-error-mean'].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 250 estimators was our best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.8014566181127296, total=   5.7s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=1, score=0.8018185108115444, total=   5.3s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=1, score=0.794671130009952, total=   5.5s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=1, score=0.7995476136620674, total=   6.9s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   24.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=1, score=0.7984980094100615, total=  10.3s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   34.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=3, score=0.8016828010494889, total=   5.7s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   40.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=3, score=0.8008233058898037, total=   6.6s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   47.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=3, score=0.7953949154075817, total=   7.1s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   54.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=3, score=0.8009500113096585, total=   6.2s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=3, score=0.7986789721317409, total=   6.1s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.8015923278747851, total=   8.7s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.8015470912874333, total=  11.5s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.7957115715190446, total=  10.8s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.7999095227324134, total=   7.5s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.7985884907709012, total=   9.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.8006875961277481, total=  13.5s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.8000542839048222, total=  13.6s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.7899212883380078, total=  12.5s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.7833521827640805, total=  11.0s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.799448063698878, total=   9.9s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.8005518863656925, total=  12.2s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.7993304985071926, total=  11.9s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.7893332127024337, total=  18.8s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.7833974213978738, total=  14.3s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.7991313789359392, total=  12.1s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.7997828643807111, total=   9.6s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.7998733375554148, total=   9.5s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.7891975029403782, total=   9.4s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.7803664329337254, total=  13.7s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.7989956568946797, total=  13.3s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.7984710033475074, total=  12.8s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.7961187008052113, total=  12.9s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.7814168099158599, total=  12.3s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.7662067405564352, total=  12.2s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.7984075280492219, total=  14.1s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.7981091106486926, total=  13.0s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.7961187008052113, total=  13.0s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.7816429928526192, total=  12.7s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.7690567744854105, total=  12.2s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.7990408975750996, total=  12.1s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.798335293585452, total=  12.3s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.7952139690581742, total=  12.3s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.77897403419886, total=  12.2s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.7664329337254014, total=  12.4s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.7993575823380383, total=  12.8s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.7924545372297114, total=  17.3s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.7877951687324708, total=  16.9s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.7714647606984529, total=  17.4s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.7515041845736259, total=  16.9s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.7988146941730003, total=  16.9s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.7947616031846557, total=  16.9s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.7903736542115263, total=  17.7s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.775083687686601, total=  16.6s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.7554851843474327, total=  16.7s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.7985432500904813, total=  16.0s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.7941282909617299, total=  15.5s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.7914140957206188, total=  15.5s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.7734551705419344, total=  15.9s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.7545351730377743, total=  15.8s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.79890517553384, total=  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 12.8min finished\n",
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.79920, std: 0.00257, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.79951, std: 0.00229, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.79947, std: 0.00219, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.79469, std: 0.00691, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.79435, std: 0.00680, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.79364, std: 0.00776, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.78812, std: 0.01267, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.78879, std: 0.01171, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.78766, std: 0.01291, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.78041, std: 0.01705, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.78285, std: 0.01584, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.78249, std: 0.01642, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 3, 'min_child_weight': 3},\n",
       " 0.79950600115765469)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=250, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='accuracy',n_jobs=1,iid=False, cv=5, verbose=10)\n",
    "gsearch1.fit(df.drop('no_show', axis=1),df.no_show)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "max_depth:3, min_child_weight:3 look like our best params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] .............. gamma=0.0, score=0.8016828010494889, total=   5.5s\n",
      "[CV] gamma=0.0 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. gamma=0.0, score=0.8008233058898037, total=   5.8s\n",
      "[CV] gamma=0.0 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. gamma=0.0, score=0.7953949154075817, total=   5.4s\n",
      "[CV] gamma=0.0 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. gamma=0.0, score=0.8009500113096585, total=   5.4s\n",
      "[CV] gamma=0.0 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   23.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. gamma=0.0, score=0.7986789721317409, total=   5.6s\n",
      "[CV] gamma=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   28.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... gamma=0.1, score=0.801637564462137, total=   5.8s\n",
      "[CV] gamma=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   34.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. gamma=0.1, score=0.8008233058898037, total=   6.2s\n",
      "[CV] gamma=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   41.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. gamma=0.1, score=0.7953949154075817, total=   5.9s\n",
      "[CV] gamma=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   47.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. gamma=0.1, score=0.8009500113096585, total=   5.7s\n",
      "[CV] gamma=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   53.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. gamma=0.1, score=0.7988599348534202, total=   5.5s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............. gamma=0.2, score=0.8015923278747851, total=   5.9s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............. gamma=0.2, score=0.8012756717633222, total=   5.8s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............. gamma=0.2, score=0.7953949154075817, total=   5.7s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............. gamma=0.2, score=0.8009952499434517, total=   6.2s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............. gamma=0.2, score=0.7988599348534202, total=  10.3s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............. gamma=0.3, score=0.8015923278747851, total=   6.8s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............. gamma=0.3, score=0.8015018547000814, total=  11.5s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............. gamma=0.3, score=0.7953949154075817, total=   7.7s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............. gamma=0.3, score=0.8009952499434517, total=   6.2s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............. gamma=0.3, score=0.7988599348534202, total=   5.5s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] ............... gamma=0.4, score=0.801637564462137, total=   5.5s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............. gamma=0.4, score=0.8009137790645073, total=   6.1s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............. gamma=0.4, score=0.7953949154075817, total=   5.5s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............. gamma=0.4, score=0.8009952499434517, total=   5.6s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] ............... gamma=0.4, score=0.798633731451321, total=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  2.7min finished\n",
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.79951, std: 0.00229, params: {'gamma': 0.0},\n",
       "  mean: 0.79953, std: 0.00227, params: {'gamma': 0.1},\n",
       "  mean: 0.79962, std: 0.00232, params: {'gamma': 0.2},\n",
       "  mean: 0.79967, std: 0.00236, params: {'gamma': 0.3},\n",
       "  mean: 0.79952, std: 0.00230, params: {'gamma': 0.4}],\n",
       " {'gamma': 0.3},\n",
       " 0.79966885655586395)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=250, max_depth=3,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test3, scoring='accuracy',n_jobs=1,iid=False, cv=5, verbose=10)\n",
    "gsearch1.fit(df.drop('no_show', axis=1),df.no_show)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma 0.3 looks like the best\n",
    "\n",
    "Let's split into train/validation and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr, test = train_test_split(df, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = tr.drop('no_show', axis=1) \n",
    "X_test = test.drop('no_show', axis=1)\n",
    "y_tr = tr.no_show\n",
    "y_test = test.no_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88421, 19), (88421,), (22106, 19), (22106,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, y_tr.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_tr.values, label=y_tr.values)\n",
    "dtest =  xgb.DMatrix(X_test.values, label=y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'max_depth': 3, 'min_child_weight':3, 'gamma':0.3, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'error'\n",
    "evallist = [(dtrain, 'train'), (dtest, 'test')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.201253\ttest-error:0.201755\n",
      "[1]\ttrain-error:0.198765\ttest-error:0.198408\n",
      "[2]\ttrain-error:0.198358\ttest-error:0.198724\n",
      "[3]\ttrain-error:0.198166\ttest-error:0.198046\n",
      "[4]\ttrain-error:0.197442\ttest-error:0.197548\n",
      "[5]\ttrain-error:0.197261\ttest-error:0.19791\n",
      "[6]\ttrain-error:0.197521\ttest-error:0.197865\n",
      "[7]\ttrain-error:0.197544\ttest-error:0.198091\n",
      "[8]\ttrain-error:0.19751\ttest-error:0.198046\n",
      "[9]\ttrain-error:0.197363\ttest-error:0.198724\n",
      "[10]\ttrain-error:0.19725\ttest-error:0.198543\n",
      "[11]\ttrain-error:0.197069\ttest-error:0.198498\n",
      "[12]\ttrain-error:0.196967\ttest-error:0.198589\n",
      "[13]\ttrain-error:0.196989\ttest-error:0.198046\n",
      "[14]\ttrain-error:0.196922\ttest-error:0.198136\n",
      "[15]\ttrain-error:0.196741\ttest-error:0.198815\n",
      "[16]\ttrain-error:0.1963\ttest-error:0.199041\n",
      "[17]\ttrain-error:0.196537\ttest-error:0.199358\n",
      "[18]\ttrain-error:0.196627\ttest-error:0.199629\n",
      "[19]\ttrain-error:0.196571\ttest-error:0.199493\n",
      "[20]\ttrain-error:0.196548\ttest-error:0.199312\n",
      "[21]\ttrain-error:0.196571\ttest-error:0.199493\n",
      "[22]\ttrain-error:0.196514\ttest-error:0.199991\n",
      "[23]\ttrain-error:0.196367\ttest-error:0.199855\n",
      "[24]\ttrain-error:0.196141\ttest-error:0.200036\n",
      "[25]\ttrain-error:0.196288\ttest-error:0.200579\n",
      "[26]\ttrain-error:0.196186\ttest-error:0.200669\n",
      "[27]\ttrain-error:0.196333\ttest-error:0.200805\n",
      "[28]\ttrain-error:0.196152\ttest-error:0.200579\n",
      "[29]\ttrain-error:0.196198\ttest-error:0.200081\n",
      "[30]\ttrain-error:0.196073\ttest-error:0.1999\n",
      "[31]\ttrain-error:0.196096\ttest-error:0.199493\n",
      "[32]\ttrain-error:0.19596\ttest-error:0.199403\n",
      "[33]\ttrain-error:0.196152\ttest-error:0.198951\n",
      "[34]\ttrain-error:0.195983\ttest-error:0.199765\n",
      "[35]\ttrain-error:0.196062\ttest-error:0.199946\n",
      "[36]\ttrain-error:0.195858\ttest-error:0.1999\n",
      "[37]\ttrain-error:0.195666\ttest-error:0.199539\n",
      "[38]\ttrain-error:0.195564\ttest-error:0.199584\n",
      "[39]\ttrain-error:0.195564\ttest-error:0.199448\n",
      "[40]\ttrain-error:0.195519\ttest-error:0.199358\n",
      "[41]\ttrain-error:0.195429\ttest-error:0.19877\n",
      "[42]\ttrain-error:0.195463\ttest-error:0.199267\n",
      "[43]\ttrain-error:0.195338\ttest-error:0.199041\n",
      "[44]\ttrain-error:0.195225\ttest-error:0.198408\n",
      "[45]\ttrain-error:0.195044\ttest-error:0.198589\n",
      "[46]\ttrain-error:0.195146\ttest-error:0.19886\n",
      "[47]\ttrain-error:0.195067\ttest-error:0.19877\n",
      "[48]\ttrain-error:0.194942\ttest-error:0.198815\n",
      "[49]\ttrain-error:0.194807\ttest-error:0.198453\n",
      "[50]\ttrain-error:0.194829\ttest-error:0.198543\n",
      "[51]\ttrain-error:0.194603\ttest-error:0.198996\n",
      "[52]\ttrain-error:0.19449\ttest-error:0.198951\n",
      "[53]\ttrain-error:0.1944\ttest-error:0.198951\n",
      "[54]\ttrain-error:0.194558\ttest-error:0.198724\n",
      "[55]\ttrain-error:0.1944\ttest-error:0.198589\n",
      "[56]\ttrain-error:0.194637\ttest-error:0.199086\n",
      "[57]\ttrain-error:0.194626\ttest-error:0.199222\n",
      "[58]\ttrain-error:0.194501\ttest-error:0.198951\n",
      "[59]\ttrain-error:0.194094\ttest-error:0.199086\n",
      "[60]\ttrain-error:0.194083\ttest-error:0.198996\n",
      "[61]\ttrain-error:0.194117\ttest-error:0.199222\n",
      "[62]\ttrain-error:0.193981\ttest-error:0.199629\n",
      "[63]\ttrain-error:0.194038\ttest-error:0.19981\n",
      "[64]\ttrain-error:0.193642\ttest-error:0.199855\n",
      "[65]\ttrain-error:0.193811\ttest-error:0.1999\n",
      "[66]\ttrain-error:0.1938\ttest-error:0.199991\n",
      "[67]\ttrain-error:0.193755\ttest-error:0.200217\n",
      "[68]\ttrain-error:0.193619\ttest-error:0.200127\n",
      "[69]\ttrain-error:0.19363\ttest-error:0.200217\n",
      "[70]\ttrain-error:0.193472\ttest-error:0.200217\n",
      "[71]\ttrain-error:0.193495\ttest-error:0.200217\n",
      "[72]\ttrain-error:0.193438\ttest-error:0.200262\n",
      "[73]\ttrain-error:0.193302\ttest-error:0.1999\n",
      "[74]\ttrain-error:0.193314\ttest-error:0.19981\n",
      "[75]\ttrain-error:0.193359\ttest-error:0.19981\n",
      "[76]\ttrain-error:0.193314\ttest-error:0.199403\n",
      "[77]\ttrain-error:0.19311\ttest-error:0.199855\n",
      "[78]\ttrain-error:0.193076\ttest-error:0.199991\n",
      "[79]\ttrain-error:0.192794\ttest-error:0.199539\n",
      "[80]\ttrain-error:0.193008\ttest-error:0.200353\n",
      "[81]\ttrain-error:0.192907\ttest-error:0.200217\n",
      "[82]\ttrain-error:0.192963\ttest-error:0.199946\n",
      "[83]\ttrain-error:0.193008\ttest-error:0.199946\n",
      "[84]\ttrain-error:0.193088\ttest-error:0.200172\n",
      "[85]\ttrain-error:0.193076\ttest-error:0.200172\n",
      "[86]\ttrain-error:0.193212\ttest-error:0.199991\n",
      "[87]\ttrain-error:0.193122\ttest-error:0.199991\n",
      "[88]\ttrain-error:0.192952\ttest-error:0.199855\n",
      "[89]\ttrain-error:0.192952\ttest-error:0.200534\n",
      "[90]\ttrain-error:0.192794\ttest-error:0.200353\n",
      "[91]\ttrain-error:0.192635\ttest-error:0.200353\n",
      "[92]\ttrain-error:0.192319\ttest-error:0.200489\n",
      "[93]\ttrain-error:0.192714\ttest-error:0.200398\n",
      "[94]\ttrain-error:0.192567\ttest-error:0.200353\n",
      "[95]\ttrain-error:0.192658\ttest-error:0.200443\n",
      "[96]\ttrain-error:0.1925\ttest-error:0.200353\n",
      "[97]\ttrain-error:0.192364\ttest-error:0.200262\n",
      "[98]\ttrain-error:0.192273\ttest-error:0.200081\n",
      "[99]\ttrain-error:0.192285\ttest-error:0.200443\n",
      "[100]\ttrain-error:0.192443\ttest-error:0.200081\n",
      "[101]\ttrain-error:0.192375\ttest-error:0.199991\n",
      "[102]\ttrain-error:0.19207\ttest-error:0.19981\n",
      "[103]\ttrain-error:0.19207\ttest-error:0.199855\n",
      "[104]\ttrain-error:0.191844\ttest-error:0.199584\n",
      "[105]\ttrain-error:0.191866\ttest-error:0.1999\n",
      "[106]\ttrain-error:0.191776\ttest-error:0.200217\n",
      "[107]\ttrain-error:0.191945\ttest-error:0.200398\n",
      "[108]\ttrain-error:0.191968\ttest-error:0.200308\n",
      "[109]\ttrain-error:0.1919\ttest-error:0.200172\n",
      "[110]\ttrain-error:0.191877\ttest-error:0.200172\n",
      "[111]\ttrain-error:0.191957\ttest-error:0.200579\n",
      "[112]\ttrain-error:0.191821\ttest-error:0.200217\n",
      "[113]\ttrain-error:0.191945\ttest-error:0.200172\n",
      "[114]\ttrain-error:0.19173\ttest-error:0.200443\n",
      "[115]\ttrain-error:0.191742\ttest-error:0.200489\n",
      "[116]\ttrain-error:0.191516\ttest-error:0.200127\n",
      "[117]\ttrain-error:0.19155\ttest-error:0.200217\n",
      "[118]\ttrain-error:0.191425\ttest-error:0.199991\n",
      "[119]\ttrain-error:0.191482\ttest-error:0.199991\n",
      "[120]\ttrain-error:0.191504\ttest-error:0.200308\n",
      "[121]\ttrain-error:0.191255\ttest-error:0.200081\n",
      "[122]\ttrain-error:0.191301\ttest-error:0.200172\n",
      "[123]\ttrain-error:0.19121\ttest-error:0.200579\n",
      "[124]\ttrain-error:0.191233\ttest-error:0.200669\n",
      "[125]\ttrain-error:0.191482\ttest-error:0.200443\n",
      "[126]\ttrain-error:0.191165\ttest-error:0.200805\n",
      "[127]\ttrain-error:0.191108\ttest-error:0.200624\n",
      "[128]\ttrain-error:0.191063\ttest-error:0.200669\n",
      "[129]\ttrain-error:0.190961\ttest-error:0.200489\n",
      "[130]\ttrain-error:0.190905\ttest-error:0.200579\n",
      "[131]\ttrain-error:0.190882\ttest-error:0.200489\n",
      "[132]\ttrain-error:0.191075\ttest-error:0.200624\n",
      "[133]\ttrain-error:0.191041\ttest-error:0.200489\n",
      "[134]\ttrain-error:0.190826\ttest-error:0.200715\n",
      "[135]\ttrain-error:0.190701\ttest-error:0.20085\n",
      "[136]\ttrain-error:0.190984\ttest-error:0.201077\n",
      "[137]\ttrain-error:0.191018\ttest-error:0.200896\n",
      "[138]\ttrain-error:0.190939\ttest-error:0.20085\n",
      "[139]\ttrain-error:0.190882\ttest-error:0.200715\n",
      "[140]\ttrain-error:0.19086\ttest-error:0.200715\n",
      "[141]\ttrain-error:0.19069\ttest-error:0.200669\n",
      "[142]\ttrain-error:0.190645\ttest-error:0.200624\n",
      "[143]\ttrain-error:0.19052\ttest-error:0.200669\n",
      "[144]\ttrain-error:0.190532\ttest-error:0.200669\n",
      "[145]\ttrain-error:0.190543\ttest-error:0.200624\n",
      "[146]\ttrain-error:0.190317\ttest-error:0.200805\n",
      "[147]\ttrain-error:0.19026\ttest-error:0.20076\n",
      "[148]\ttrain-error:0.19026\ttest-error:0.20085\n",
      "[149]\ttrain-error:0.190192\ttest-error:0.200579\n",
      "[150]\ttrain-error:0.190158\ttest-error:0.200443\n",
      "[151]\ttrain-error:0.190226\ttest-error:0.200624\n",
      "[152]\ttrain-error:0.190091\ttest-error:0.200579\n",
      "[153]\ttrain-error:0.190113\ttest-error:0.200489\n",
      "[154]\ttrain-error:0.190034\ttest-error:0.200534\n",
      "[155]\ttrain-error:0.190079\ttest-error:0.200489\n",
      "[156]\ttrain-error:0.19\ttest-error:0.200443\n",
      "[157]\ttrain-error:0.189819\ttest-error:0.200669\n",
      "[158]\ttrain-error:0.189876\ttest-error:0.200353\n",
      "[159]\ttrain-error:0.18974\ttest-error:0.200353\n",
      "[160]\ttrain-error:0.189797\ttest-error:0.200489\n",
      "[161]\ttrain-error:0.189661\ttest-error:0.200579\n",
      "[162]\ttrain-error:0.189627\ttest-error:0.200624\n",
      "[163]\ttrain-error:0.18965\ttest-error:0.200896\n",
      "[164]\ttrain-error:0.18974\ttest-error:0.20085\n",
      "[165]\ttrain-error:0.18983\ttest-error:0.200489\n",
      "[166]\ttrain-error:0.189548\ttest-error:0.20076\n",
      "[167]\ttrain-error:0.189502\ttest-error:0.200669\n",
      "[168]\ttrain-error:0.189536\ttest-error:0.20076\n",
      "[169]\ttrain-error:0.189435\ttest-error:0.200624\n",
      "[170]\ttrain-error:0.189446\ttest-error:0.201167\n",
      "[171]\ttrain-error:0.189412\ttest-error:0.201167\n",
      "[172]\ttrain-error:0.189514\ttest-error:0.201393\n",
      "[173]\ttrain-error:0.189446\ttest-error:0.200579\n",
      "[174]\ttrain-error:0.189469\ttest-error:0.200353\n",
      "[175]\ttrain-error:0.189389\ttest-error:0.200579\n",
      "[176]\ttrain-error:0.189344\ttest-error:0.200805\n",
      "[177]\ttrain-error:0.189186\ttest-error:0.200941\n",
      "[178]\ttrain-error:0.189061\ttest-error:0.20085\n",
      "[179]\ttrain-error:0.189175\ttest-error:0.201167\n",
      "[180]\ttrain-error:0.189084\ttest-error:0.200986\n",
      "[181]\ttrain-error:0.189084\ttest-error:0.20085\n",
      "[182]\ttrain-error:0.189016\ttest-error:0.200986\n",
      "[183]\ttrain-error:0.189016\ttest-error:0.200579\n",
      "[184]\ttrain-error:0.188813\ttest-error:0.200579\n",
      "[185]\ttrain-error:0.188688\ttest-error:0.20076\n",
      "[186]\ttrain-error:0.18862\ttest-error:0.20076\n",
      "[187]\ttrain-error:0.188688\ttest-error:0.200443\n",
      "[188]\ttrain-error:0.188598\ttest-error:0.200353\n",
      "[189]\ttrain-error:0.18853\ttest-error:0.200127\n",
      "[190]\ttrain-error:0.18896\ttest-error:0.199946\n",
      "[191]\ttrain-error:0.189163\ttest-error:0.200805\n",
      "[192]\ttrain-error:0.189129\ttest-error:0.200669\n",
      "[193]\ttrain-error:0.189197\ttest-error:0.200398\n",
      "[194]\ttrain-error:0.18905\ttest-error:0.200579\n",
      "[195]\ttrain-error:0.189095\ttest-error:0.200308\n",
      "[196]\ttrain-error:0.188903\ttest-error:0.200217\n",
      "[197]\ttrain-error:0.188439\ttest-error:0.200579\n",
      "[198]\ttrain-error:0.188541\ttest-error:0.200308\n",
      "[199]\ttrain-error:0.188338\ttest-error:0.201077\n",
      "[200]\ttrain-error:0.188451\ttest-error:0.201258\n",
      "[201]\ttrain-error:0.188383\ttest-error:0.201258\n",
      "[202]\ttrain-error:0.188021\ttest-error:0.201619\n",
      "[203]\ttrain-error:0.188066\ttest-error:0.201393\n",
      "[204]\ttrain-error:0.187897\ttest-error:0.201439\n",
      "[205]\ttrain-error:0.188168\ttest-error:0.200715\n",
      "[206]\ttrain-error:0.188157\ttest-error:0.200805\n",
      "[207]\ttrain-error:0.188111\ttest-error:0.200805\n",
      "[208]\ttrain-error:0.188055\ttest-error:0.200489\n",
      "[209]\ttrain-error:0.187908\ttest-error:0.20076\n",
      "[210]\ttrain-error:0.187783\ttest-error:0.200715\n",
      "[211]\ttrain-error:0.187976\ttest-error:0.200262\n",
      "[212]\ttrain-error:0.187964\ttest-error:0.200353\n",
      "[213]\ttrain-error:0.188044\ttest-error:0.200398\n",
      "[214]\ttrain-error:0.187874\ttest-error:0.200353\n",
      "[215]\ttrain-error:0.187806\ttest-error:0.200353\n",
      "[216]\ttrain-error:0.18767\ttest-error:0.200217\n",
      "[217]\ttrain-error:0.187625\ttest-error:0.200217\n",
      "[218]\ttrain-error:0.187591\ttest-error:0.200398\n",
      "[219]\ttrain-error:0.187591\ttest-error:0.200127\n",
      "[220]\ttrain-error:0.187546\ttest-error:0.200036\n",
      "[221]\ttrain-error:0.187444\ttest-error:0.200217\n",
      "[222]\ttrain-error:0.187444\ttest-error:0.200172\n",
      "[223]\ttrain-error:0.187659\ttest-error:0.200262\n",
      "[224]\ttrain-error:0.187489\ttest-error:0.200262\n",
      "[225]\ttrain-error:0.187422\ttest-error:0.200398\n",
      "[226]\ttrain-error:0.187478\ttest-error:0.200579\n",
      "[227]\ttrain-error:0.187591\ttest-error:0.200669\n",
      "[228]\ttrain-error:0.18758\ttest-error:0.200353\n",
      "[229]\ttrain-error:0.18758\ttest-error:0.200262\n",
      "[230]\ttrain-error:0.187659\ttest-error:0.200081\n",
      "[231]\ttrain-error:0.187682\ttest-error:0.200172\n",
      "[232]\ttrain-error:0.187591\ttest-error:0.200036\n",
      "[233]\ttrain-error:0.187716\ttest-error:0.200308\n",
      "[234]\ttrain-error:0.187817\ttest-error:0.200127\n",
      "[235]\ttrain-error:0.18775\ttest-error:0.200398\n",
      "[236]\ttrain-error:0.187716\ttest-error:0.20076\n",
      "[237]\ttrain-error:0.187817\ttest-error:0.200534\n",
      "[238]\ttrain-error:0.187716\ttest-error:0.200579\n",
      "[239]\ttrain-error:0.187399\ttest-error:0.200489\n",
      "[240]\ttrain-error:0.18741\ttest-error:0.200489\n",
      "[241]\ttrain-error:0.187422\ttest-error:0.200579\n",
      "[242]\ttrain-error:0.187388\ttest-error:0.200262\n",
      "[243]\ttrain-error:0.187399\ttest-error:0.200308\n",
      "[244]\ttrain-error:0.187399\ttest-error:0.200624\n",
      "[245]\ttrain-error:0.187422\ttest-error:0.200534\n",
      "[246]\ttrain-error:0.187455\ttest-error:0.200624\n",
      "[247]\ttrain-error:0.187444\ttest-error:0.200534\n",
      "[248]\ttrain-error:0.187376\ttest-error:0.200715\n",
      "[249]\ttrain-error:0.187331\ttest-error:0.200398\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, dtrain, num_boost_round=250, evals=evallist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
